{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, obs_dim, n_action, seed=0,\n",
    "                 discount_factor = 0.995, epsilon_decay = 0.999, epsilon_min = 0.01,\n",
    "                 learning_rate = 1e-3, # Step size for Adam\n",
    "                 batch_size = 64, \n",
    "                 memory_size = 2000, hidden_unit_size = 64):\n",
    "        \n",
    "        self.seed = seed \n",
    "        \n",
    "        # Environment Information\n",
    "        self.obs_dim = obs_dim\n",
    "        self.n_action = n_action\n",
    "        self.discount_factor = discount_factor\n",
    "        \n",
    "        # Epsilon Greedy Policy\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "        # Network Hyperparameters\n",
    "        self.hidden_unit_size = hidden_unit_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.train_start = 1000\n",
    "\n",
    "        # Experience Replay\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        \n",
    "        # Define Computational Graph in TF\n",
    "        self.g = tf.Graph()\n",
    "        with self.g.as_default():\n",
    "            self.build_placeholders()\n",
    "            self.build_model()\n",
    "            self.build_loss()\n",
    "            self.build_update_operation()\n",
    "            self.init_session() # Initialize all parameters in graph\n",
    "    \n",
    "    def build_placeholders(self): # Build input and output place holder\n",
    "        self.obs_ph = tf.placeholder(tf.float32, (None, self.obs_dim), 'obs') # Input state\n",
    "        self.target_ph = tf.placeholder(tf.float32, (None, self.n_action), 'target') # TD target\n",
    "        self.learning_rate_ph = tf.placeholder(tf.float32, (), 'lr')        \n",
    "    \n",
    "    def build_model(self): # Build networks\n",
    "        hid1_size = self.hidden_unit_size\n",
    "        hid2_size = self.hidden_unit_size\n",
    "        \n",
    "        with tf.variable_scope('q_prediction'): # Prediction Network / Two layered perceptron / Training Parameters\n",
    "            out = tf.layers.dense(self.obs_ph, hid1_size, tf.tanh, # Tangent Hyperbolic Activation\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='hidden1')\n",
    "            out = tf.layers.dense(out, hid2_size, tf.tanh, # Tangent Hyperbolic Activation\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='hidden2')\n",
    "            self.q_predict = tf.layers.dense(out, self.n_action, # Linear Layer\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='q_predict')\n",
    "                        \n",
    "        with tf.variable_scope('q_target'): # Target Network / Two layered perceptron / Old Parameters\n",
    "            out = tf.layers.dense(self.obs_ph, hid1_size, tf.tanh, # Tangent Hyperbolic Activation\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='hidden1')\n",
    "            out = tf.layers.dense(out, hid2_size, tf.tanh, # Tangent Hyperbolic Activation\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='hidden2')\n",
    "            self.q_predict_old = tf.layers.dense(out, self.n_action, # Linear Layer\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='q_predict')\n",
    "        \n",
    "        self.weights = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='q_prediction') # Get Prediction network's Parameters\n",
    "        self.weights_old = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='q_target') # Get Target network's Parameters\n",
    "\n",
    "    def build_loss(self):\n",
    "        self.loss = 0.5*tf.reduce_mean(tf.square(self.target_ph - self.q_predict)) # Squared Error\n",
    "        self.optim = tf.train.AdamOptimizer(learning_rate=self.learning_rate_ph).minimize(self.loss) # AdamOptimizer (Gradient Descent Algorithm)\n",
    "            \n",
    "    def build_update_operation(self): # Define parameter update operation in TF graph\n",
    "        update_ops = [] \n",
    "        for var, var_old in zip(self.weights, self.weights_old): # Update Target Network's Parameter with Prediction Network\n",
    "            update_ops.append(var_old.assign(var))\n",
    "        self.update_ops = update_ops\n",
    "        \n",
    "    def init_session(self):\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=config,graph=self.g) # Initialize session\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(self.update_ops)\n",
    "        \n",
    "    def update_target(self): # Update parameters\n",
    "        self.sess.run(self.update_ops)\n",
    "        \n",
    "    def update_policy(self):\n",
    "        if self.epsilon > self.epsilon_min: # Update epsilon\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "    def get_prediction_old(self, obs): # Get Q value from target network\n",
    "        q_value_old = self.sess.run(self.q_predict_old,feed_dict={self.obs_ph:obs})        \n",
    "        return q_value_old\n",
    "        \n",
    "    def get_prediction(self, obs): # Get Q value from prediction network\n",
    "        q_value = self.sess.run(self.q_predict,feed_dict={self.obs_ph:obs})        \n",
    "        return q_value\n",
    "    \n",
    "    def get_action(self, obs): # Epsilon Greedy policy\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.n_action)\n",
    "        else:\n",
    "            q_value = self.get_prediction([obs])\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    def add_experience(self, obs, action, reward, next_obs, done): # Add experience to memory\n",
    "        self.memory.append((obs, action, reward, next_obs, done))\n",
    "\n",
    "    def train_model(self):\n",
    "        loss = np.nan\n",
    "        n_entries = len(self.memory)\n",
    "            \n",
    "        if n_entries > self.train_start: # Start training when the number of experience is greater than batch size\n",
    "            \n",
    "            # Randomly sample batch\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            \n",
    "            observations = np.zeros((self.batch_size, self.obs_dim))\n",
    "            next_observations = np.zeros((self.batch_size, self.obs_dim))\n",
    "            actions, rewards, dones = [], [], []\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                observations[i] = mini_batch[i][0]\n",
    "                actions.append(mini_batch[i][1])\n",
    "                rewards.append(mini_batch[i][2])\n",
    "                next_observations[i] = mini_batch[i][3]\n",
    "                dones.append(mini_batch[i][4])\n",
    "\n",
    "            target = self.get_prediction(observations)\n",
    "            next_q_value = self.get_prediction_old(next_observations)\n",
    "\n",
    "            # BELLMAN UPDATE RULE \n",
    "            for i in range(self.batch_size):\n",
    "                if dones[i]:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else:\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * (np.amax(next_q_value[i]))\n",
    "\n",
    "            loss, _ = self.sess.run([self.loss, self.optim], \n",
    "                                 feed_dict={self.obs_ph:observations,self.target_ph:target,self.learning_rate_ph:self.learning_rate})                        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Observation space\n",
      "<class 'gym.spaces.box.Box'>\n",
      "(4,)\n",
      "Dimension:4\n",
      "High: [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "Low: [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "\n",
      "Action space\n",
      "<class 'gym.spaces.discrete.Discrete'>\n",
      "Total 2 actions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "obs_space = env.observation_space\n",
    "print('Observation space')\n",
    "print(type(obs_space))\n",
    "print(obs_space.shape)\n",
    "print(\"Dimension:{}\".format(obs_space.shape[0]))\n",
    "print(\"High: {}\".format(obs_space.high))\n",
    "print(\"Low: {}\".format(obs_space.low))\n",
    "print()\n",
    "\n",
    "act_space = env.action_space\n",
    "print('Action space')\n",
    "print(type(act_space))\n",
    "print(\"Total {} actions\".format(act_space.n))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1000] loss : nan, return : 11.000\n",
      "[100/1000] loss : 55.819, return : 10.300\n",
      "[200/1000] loss : 1341.734, return : 101.100\n",
      "[300/1000] loss : 271.446, return : 14.600\n",
      "[400/1000] loss : 3873.282, return : 117.600\n",
      "[487/1000] loss : 5254.369, return : 500.000\n",
      "The problem is solved with 487 episodes\n"
     ]
    }
   ],
   "source": [
    "env.seed(seed)\n",
    "max_t = env.spec.max_episode_steps\n",
    "expert = DQNAgent(env.observation_space.high.shape[0],env.action_space.n)\n",
    "\n",
    "avg_return_list = []\n",
    "avg_return = deque(maxlen=10)\n",
    "avg_loss = deque(maxlen=10)\n",
    "nepisodes = 1000\n",
    "for i in range(nepisodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "    for t in range(max_t):\n",
    "        # Get transition\n",
    "        action = expert.get_action(obs)\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "\n",
    "        # Add experience\n",
    "        expert.add_experience(obs,action,reward,next_obs,done)\n",
    "\n",
    "        # Online update perdiction network parameter\n",
    "        loss = expert.train_model()\n",
    "\n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "        total_loss += loss\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        # Update target network parameter\n",
    "        expert.update_target()\n",
    "        expert.update_policy()\n",
    "\n",
    "    avg_return.append(total_reward)\n",
    "    avg_loss.append(total_loss)\n",
    "    avg_return_list.append(np.mean(avg_return))\n",
    "\n",
    "    if (np.mean(avg_return) > 490): # Threshold return to success cartpole\n",
    "\n",
    "        print('[{}/{}] loss : {:.3f}, return : {:.3f}'.format(i,nepisodes, np.mean(avg_loss), np.mean(avg_return)))\n",
    "        print('The problem is solved with {} episodes'.format(i))\n",
    "        break\n",
    "\n",
    "    if (i%100)==0:\n",
    "        print('[{}/{}] loss : {:.3f}, return : {:.3f}'.format(i,nepisodes, np.mean(avg_loss), np.mean(avg_return)))\n",
    "\n",
    "dqn_return_list = avg_return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Learning from Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNfDAgent:\n",
    "    def __init__(self, obs_dim, n_action, seed=0,\n",
    "                 discount_factor = 0.995, epsilon_decay = 0.999, epsilon_min = 0.01,\n",
    "                 learning_rate = 1e-3, # Step size for Adam\n",
    "                 batch_size = 64, \n",
    "                 memory_size = 2000, hidden_unit_size = 64):\n",
    "        \n",
    "        self.seed = seed \n",
    "        \n",
    "        # Environment Information\n",
    "        self.obs_dim = obs_dim\n",
    "        self.n_action = n_action\n",
    "        self.discount_factor = discount_factor\n",
    "        \n",
    "        # Epsilon Greedy Policy\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "        # Network Hyperparameters\n",
    "        self.hidden_unit_size = hidden_unit_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.train_start = 1000\n",
    "\n",
    "        # Experience Replay\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        \n",
    "        # Define Computational Graph in TF\n",
    "        self.g = tf.Graph()\n",
    "        with self.g.as_default():\n",
    "            self.build_placeholders()\n",
    "            self.build_model()\n",
    "            self.build_loss()\n",
    "            self.build_update_operation()\n",
    "            self.init_session() # Initialize all parameters in graph\n",
    "    \n",
    "    def build_placeholders(self): # Build input and output place holder\n",
    "        self.obs_ph = tf.placeholder(tf.float32, (None, self.obs_dim), 'obs') # Input state\n",
    "        self.target_ph = tf.placeholder(tf.float32, (None, self.n_action), 'target') # TD target\n",
    "        self.isdemo_ph = tf.placeholder(tf.float32,(None, ), name=\"isdemo\") # Flag : Expert = 1, Non expert = 0\n",
    "        self.action_batch = tf.placeholder(tf.int32, (None, ), name=\"action_batch\")\n",
    "        self.learning_rate_ph = tf.placeholder(tf.float32, (), 'lr')        \n",
    "    \n",
    "    def build_model(self): # Build networks\n",
    "        hid1_size = self.hidden_unit_size\n",
    "        hid2_size = self.hidden_unit_size\n",
    "        \n",
    "        with tf.variable_scope('q_prediction'): # Prediction Network / Two layered perceptron / Training Parameters\n",
    "            out = tf.layers.dense(self.obs_ph, hid1_size, tf.tanh, # Tangent Hyperbolic Activation\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='hidden1')\n",
    "            out = tf.layers.dense(out, hid2_size, tf.tanh, # Tangent Hyperbolic Activation\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='hidden2')\n",
    "            self.q_predict = tf.layers.dense(out, self.n_action, # Linear Layer\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='q_predict')\n",
    "                        \n",
    "        with tf.variable_scope('q_target'): # Target Network / Two layered perceptron / Old Parameters\n",
    "            out = tf.layers.dense(self.obs_ph, hid1_size, tf.tanh, # Tangent Hyperbolic Activation\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='hidden1')\n",
    "            out = tf.layers.dense(out, hid2_size, tf.tanh, # Tangent Hyperbolic Activation\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='hidden2')\n",
    "            self.q_predict_old = tf.layers.dense(out, self.n_action, # Linear Layer\n",
    "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01,seed=self.seed), name='q_predict')\n",
    "        \n",
    "        self.weights = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='q_prediction') # Get Prediction network's Parameters\n",
    "        self.weights_old = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='q_target') # Get Target network's Parameters\n",
    "\n",
    "    def build_loss(self):\n",
    "        def loss_l(ae, a): # Action mismatch loss\n",
    "            return 0.0 if ae == a else 0.8\n",
    "\n",
    "        def loss_jeq(Q_predict): # Large Margin Loss for expert's demo\n",
    "            jeq = 0.0\n",
    "            for i in range(self.batch_size):\n",
    "                ae = self.action_batch[i]\n",
    "                max_value = float(\"-inf\")\n",
    "                for a in range(self.n_action):\n",
    "                    max_value = tf.maximum(Q_predict[i][a] + loss_l(ae, a), max_value)\n",
    "                jeq += self.isdemo_ph[i] * (max_value - Q_predict[i][ae])\n",
    "            return jeq\n",
    "        \n",
    "        self.loss_jeq = loss_jeq(self.q_predict) # Expert's Loss\n",
    "        self.loss_dq = 0.5*tf.reduce_mean(tf.square(self.target_ph - self.q_predict))\n",
    "        self.loss = self.loss_dq + self.loss_jeq\n",
    "        self.optim = tf.train.AdamOptimizer(learning_rate=self.learning_rate_ph).minimize(self.loss) # AdamOptimizer (Gradient Descent Algorithm)\n",
    "            \n",
    "    def build_update_operation(self): # Define parameter update operation in TF graph\n",
    "        update_ops = [] \n",
    "        for var, var_old in zip(self.weights, self.weights_old): # Update Target Network's Parameter with Prediction Network\n",
    "            update_ops.append(var_old.assign(var))\n",
    "        self.update_ops = update_ops\n",
    "        \n",
    "    def init_session(self):\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=config,graph=self.g) # Initialize session\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(self.update_ops)\n",
    "        \n",
    "    def update_target(self): # Update parameters\n",
    "        self.sess.run(self.update_ops)\n",
    "        \n",
    "    def update_policy(self):\n",
    "        if self.epsilon > self.epsilon_min: # Update epsilon\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "    def get_prediction_old(self, obs): # Get Q value from target network\n",
    "        q_value_old = self.sess.run(self.q_predict_old,feed_dict={self.obs_ph:obs})        \n",
    "        return q_value_old\n",
    "        \n",
    "    def get_prediction(self, obs): # Get Q value from prediction network\n",
    "        q_value = self.sess.run(self.q_predict,feed_dict={self.obs_ph:obs})        \n",
    "        return q_value\n",
    "    \n",
    "    def get_action(self, obs): # Epsilon Greedy policy\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.n_action)\n",
    "        else:\n",
    "            q_value = self.get_prediction([obs])\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    def add_experience(self, obs, action, reward, next_obs, done, isdemo=False): # Add experience to memory\n",
    "        self.memory.append((obs, action, reward, next_obs, done, isdemo)) # Now, demo flag is stored\n",
    "\n",
    "    def train_model(self):\n",
    "        loss = np.nan\n",
    "        n_entries = len(self.memory)\n",
    "            \n",
    "        if n_entries > self.train_start: # Start training when the number of experience is greater than batch size\n",
    "            \n",
    "            # Randomly sample batch\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            \n",
    "            observations = np.zeros((self.batch_size, self.obs_dim))\n",
    "            next_observations = np.zeros((self.batch_size, self.obs_dim))\n",
    "            actions, rewards, dones, isdemo = [], [], [], []\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                observations[i] = mini_batch[i][0]\n",
    "                actions.append(mini_batch[i][1])\n",
    "                rewards.append(mini_batch[i][2])\n",
    "                next_observations[i] = mini_batch[i][3]\n",
    "                dones.append(mini_batch[i][4])\n",
    "                isdemo.append(mini_batch[i][5])\n",
    "\n",
    "            target = self.get_prediction(observations)\n",
    "            next_q_value = self.get_prediction_old(next_observations)\n",
    "\n",
    "            # BELLMAN UPDATE RULE \n",
    "            for i in range(self.batch_size):\n",
    "                if dones[i]:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else:\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * (np.amax(next_q_value[i]))\n",
    "\n",
    "            loss, _ = self.sess.run([self.loss, self.optim], \n",
    "                                 feed_dict={self.obs_ph:observations,self.target_ph:target,self.learning_rate_ph:self.learning_rate,self.isdemo_ph:isdemo,self.action_batch:actions})                        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert's Performance : 500.00\n"
     ]
    }
   ],
   "source": [
    "agent = DQNfDAgent(env.observation_space.high.shape[0],env.action_space.n)\n",
    "ndemos = 10\n",
    "experts_return = deque(maxlen=ndemos)\n",
    "for i in range(ndemos+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "    for t in range(max_t):\n",
    "        # Get transition\n",
    "        action = expert.get_action(obs)\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "\n",
    "        # Add experience\n",
    "        agent.add_experience(obs,action,reward,next_obs,done,isdemo=True)\n",
    "\n",
    "        # Online update perdiction network parameter\n",
    "        loss = agent.train_model()\n",
    "\n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "        total_loss += loss\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    experts_return.append(total_reward)\n",
    "\n",
    "print(\"Expert's Performance : %.02f\"%np.mean(experts_return))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DQNfD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1000] loss : 613.261, return : 12.000\n",
      "[100/1000] loss : 1218.991, return : 120.200\n",
      "[147/1000] loss : 6909.178, return : 496.100\n",
      "The problem is solved with 147 episodes\n"
     ]
    }
   ],
   "source": [
    "avg_return_list = []\n",
    "avg_return = deque(maxlen=10)\n",
    "avg_loss = deque(maxlen=10)\n",
    "nepisodes = 1000\n",
    "for i in range(nepisodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "    for t in range(max_t):\n",
    "        # Get transition\n",
    "        action = agent.get_action(obs)\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "\n",
    "        # Add experience\n",
    "        agent.add_experience(obs,action,reward,next_obs,done,isdemo=False)\n",
    "\n",
    "        # Online update perdiction network parameter\n",
    "        loss = agent.train_model()\n",
    "\n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "        total_loss += loss\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        # Update target network parameter\n",
    "        agent.update_target()\n",
    "        agent.update_policy()\n",
    "\n",
    "    avg_return.append(total_reward)\n",
    "    avg_loss.append(total_loss)\n",
    "    avg_return_list.append(np.mean(avg_return))\n",
    "\n",
    "    if (np.mean(avg_return) > 490): # Threshold return to success cartpole\n",
    "\n",
    "        print('[{}/{}] loss : {:.3f}, return : {:.3f}'.format(i,nepisodes, np.mean(avg_loss), np.mean(avg_return)))\n",
    "        print('The problem is solved with {} episodes'.format(i))\n",
    "        break\n",
    "\n",
    "    if (i%100)==0:\n",
    "        print('[{}/{}] loss : {:.3f}, return : {:.3f}'.format(i,nepisodes, np.mean(avg_loss), np.mean(avg_return)))\n",
    "\n",
    "dqfd_return_list = avg_return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dqfd_return_list,label=\"DQfD\")\n",
    "plt.plot(dqn_return_list,label=\"DQN\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
